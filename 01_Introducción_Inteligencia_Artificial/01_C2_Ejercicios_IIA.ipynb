{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Inteligencia Artificial\n",
    "\n",
    "## CLASE 2\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- [Cheatsheet de Latex](https://www.caam.rice.edu/~heinken/latex/symbols.pdf)\n",
    "- [DRIVE](https://drive.google.com/drive/folders/1TDRvlwfSgLI39gHXgVhWlSaRJ-aTSaDE?usp=sharing)\n",
    "\n",
    "## Comentarios sobre el estado del documento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# MATPLOTLIB & SNS\n",
    "# from mpl_toolkits import mplot3d\n",
    "# from matplotlib import cm\n",
    "# from matplotlib_venn import venn2\n",
    "# import seaborn as sns\n",
    "\n",
    "# MATH & RANDOM\n",
    "# import math\n",
    "# import numpy.random as random\n",
    "# import scipy.stats as stats\n",
    "# random.seed(42)\n",
    "\n",
    "#PANDAS\n",
    "# import pandas as pd\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3 \n",
    "\"\"\"\n",
    "Implementacion basica de K-means en Numpy\n",
    "K-means es uno de los algoritmos más básicos en Machine Learning no supervisado.\n",
    "Es un algoritmo de clusterización, que agrupa los datos que comparten características similares.\n",
    "Recordemos que entendemos datos como n realizaciones del vector aleatorio X.\n",
    "El algoritmo K-means funcione de la siguiente manera:\n",
    "1. El usuario selecciona la cantidad de clusters a crear (n).\n",
    "2. Se seleccionan n elementos aleatorios de X como posiciones iniciales del los centroides C.\n",
    "3. Se calcula la distancia entre todos los puntos en X y todos los puntos en C.\n",
    "4. Para cada punto en X se selecciona el centroide más cercano de C.\n",
    "5. Se recalculan los centroides C a partir de usar las filas de X que pertenecen a cada centroide.\n",
    "6. Se itera entre 3 y 5 una cantidad fija de veces o hasta que la posición de los centroides no cambie.\n",
    "Implementar la función def k_means(X, n) de manera tal que al finalizar devuelva la posición de los\n",
    "centroides y a que cluster pertenece cada fila de X.\n",
    "Hint: para (2) utilizar funciones de np.random, para (3) y (4) usar los ejercicios anteriores,\n",
    "para (5) es válido utilizar un for. Iterar 10 veces entre (3) y (5).\n",
    "\"\"\"\n",
    "mean = 5\n",
    "std = 2\n",
    "SIZE = 1000\n",
    "\n",
    "def sinthetic_data(mean, std, SIZE, n_clusters , separation):\n",
    "    sint_data = np.zeros([SIZE, n_clusters])\n",
    "    classes = np.zeros([SIZE])\n",
    "    for i in range(n_clusters):\n",
    "            from_ = i * int(SIZE/n_clusters)\n",
    "            to_ = i * int(SIZE/n_clusters) + int(SIZE/n_clusters)\n",
    "            sint_data[from_:to_,i] = separation[i] * np.array([np.random.normal(mean, std)])\n",
    "            classes[from_:to_] = i + 1\n",
    "    sint_data += np.random.normal(0, 3, size=sint_data.shape)\n",
    "    \n",
    "    return sint_data, classes\n",
    "\n",
    "simulated_data, simulated_data_classes = sinthetic_data(2, 0.5, 1000, 3, [1, 5, 10])\n",
    "\n",
    "\n",
    "X = simulated_data\n",
    "n_clusters = 3\n",
    "MAX_ITER = 10\n",
    "\n",
    "    \n",
    "def redefine_centroids(X, centroids, n_clusters):    \n",
    "    distance = np.sqrt(np.sum((centroids[:,None] - X)**2, axis=2))\n",
    "    centroid_with_min_distance = np.argmin(distance, axis=0)\n",
    "\n",
    "    for i in range(centroids.shape[0]):\n",
    "        centroids[i] = np.mean( X[centroid_with_min_distance == i, :], axis = 0)\n",
    "    return centroids, centroid_with_min_distance\n",
    "\n",
    "\n",
    "def kmeans(X, n_clusters):\n",
    "    MAX_ITER = 20\n",
    "    centroids = np.eye(n_clusters, X.shape[1])\n",
    "        \n",
    "    for i in range(MAX_ITER):\n",
    "        centroids, clusters = redefine_centroids(X, centroids, n_clusters)\n",
    "        \n",
    "    return centroids, clusters\n",
    "\n",
    "centroids_prueba, clusters_prueba = kmeans(X, n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "\"\"\" Ejercicio #5 | Utilizar numpy para simular una exponencial de parámetro lambda\n",
    "Hint:\n",
    "● Hacer una función que genere n muestras de la variable aleatoria X\n",
    "● Utilizar el resultado obtenido en la diapositiva anterior\n",
    "● Utilizar np.random.uniform\"\"\"\n",
    "\n",
    "def simular_exponencial(param, n_simulaciones):\n",
    "    simu_U = np.random.uniform(0,1,n_simulaciones)\n",
    "    simu_exp = -np.log(1 - simu_U) / param\n",
    "    return simu_exp\n",
    "\n",
    "exp_ordenada = np.sort(simular_exponencial(3, 1000))\n",
    "plt.hist(exp_ordenada, bins= int(1000**0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 9\n",
    "\"\"\" Ejercicio #9 | Remover filas y columnas con NaNs en un dataset\n",
    "Dato un dataset, hacer una funcion que utilizando numpy filtre las columnas y las filas que tienen NaNs/\"\"\"\n",
    "\n",
    "def erase_row_col_nan(data):\n",
    "    nan_matrix = np.isnan(data)\n",
    "    mask_row_ful = nan_matrix.sum(axis=1) == 0\n",
    "    mask_col_ful = nan_matrix.sum(axis=0) == 0\n",
    "    \n",
    "    non_nan_data = data[mask_row_ful, mask_col_ful]\n",
    "    return non_nan_data\n",
    "a = np.array([[np.nan,5],[1,5]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean of the columns are: [ 2.32210746  3.43582469 10.00995438]\n",
      "the filed dataset is:\n",
      " [[ 9.45321797  3.43582469 10.00995438]\n",
      " [ 5.50646231 -2.49276068  3.36316543]\n",
      " [ 9.04154328  3.43582469 10.00995438]\n",
      " [ 0.16932173 13.31648997 -0.33303124]\n",
      " [ 1.91894574 20.84824294 -0.1984794 ]\n",
      " [-0.32115295  3.43582469 10.00995438]\n",
      " [-2.28360007 -2.45796948 29.75436684]\n",
      " [ 4.5280377   3.43582469 10.00995438]\n",
      " [-3.73438112 -2.82732403 28.54722444]\n",
      " [-1.05732    -5.77173058 -1.07351976]]\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 10\n",
    "\"\"\"Reemplazar NaNs por la media de la columna.\n",
    "Dato un dataset, hacer una función que utilizando numpy reemplace los NaNs por la media de la columna.\"\"\"\n",
    "\n",
    "def replace_nans_colmean(data):\n",
    "    nan_matrix = np.isnan(data)\n",
    "    col_means = np.nanmean(data, axis=0)\n",
    "    for i in range(col_means.shape[0]):\n",
    "        data[:,i] = np.where(nan_matrix[:,i] == True, col_means[i], data[:,i])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data, i = sinthetic_data(10,1, 10, 3, [1,2,3])\n",
    "\n",
    "for i in [0, 2, 5, 7]:\n",
    "    for j in [1, 2]:\n",
    "        data[i, j]= np.nan\n",
    "        \n",
    "print('the mean of the columns are:', np.nanmean(data, axis=0))\n",
    "        \n",
    "print('the filed dataset is:\\n', replace_nans_colmean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 11\n",
    "\n",
    "'''Dado un dataset X separarlo en 70 / 20 / 10\n",
    "Como veremos en las próximas clases, en problemas de Machine Learning es fundamental que separemos\n",
    "los datasets de n muestras, en 3 datasets de la siguiente manera:\n",
    "● Training dataset: los datos que utilizaremos para entrenar nuestros modelos. 70% de las muestras.\n",
    "● Validation dataset: los datos que para calcular métricas y ajustar los parámetros de nuestros modelos.\n",
    "20% de las muestras.\n",
    "\n",
    "● Testing dataset: una vez que entrenamos los modelos y encontramos los parametros optimos de los\n",
    "mismos, el testing dataset se lo utiliza para computar las métricas finales de nuestros modelos y\n",
    "analizar cómo se comporta con respecto a la generalización.\n",
    "A partir de utilizar np.random.permutation hacer un método que dado un dataset, devuelva los 3 datasets\n",
    "como nuevos numpy arrays.'''\n",
    "\n",
    "def train_test_split(data, test_size = 0.1, validation_size = 0.2):\n",
    "    # divides the dataset by permutating, masking and slicing into train and split\n",
    "    SIZE = data.shape[0]\n",
    "    data_total = data\n",
    "    idx = np.arange(0, SIZE)\n",
    "    \n",
    "    train_interval = int((1 - test_size - validation_size) * SIZE)\n",
    "    validation_interval = int((1 - test_size) * SIZE)\n",
    "\n",
    "    # permutate\n",
    "    perm_idx = np.random.permutation(idx)\n",
    "\n",
    "    # generate index slice\n",
    "    train_idx = perm_idx[:train_interval]\n",
    "    validation_idx = perm_idx[train_interval: validation_interval]\n",
    "    test_idx = perm_idx[validation_interval:]\n",
    "\n",
    "    # slice dataset\n",
    "    train_data = data_total[train_idx]\n",
    "    validation_data = data_total[validation_idx]\n",
    "    test_data = data_total[test_idx]\n",
    "\n",
    "    return train_data, validation_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio # 12 - Integrador Clase #1 y Clase #2\n",
    "'''\n",
    "Aplicar todo lo visto en clase a un ejercicio de clusterización básico.\n",
    "1. Generar un dataset sintético que clusterice data en 4 clusters utilizando números random.\n",
    "a. Utilizar 4 dimensiones.\n",
    "b. Generar un dataset con 100K de muestras.\n",
    "2. Cambiar algunos puntos de manera aleatoria y agregar NaN (0.1% del dataset).\n",
    "3. Guardar el dataset en un .pkl\n",
    "4. Cargar el dataset con Numpy desde el .pkl\n",
    "5. Completar NaN con la media de cada feature.\n",
    "6. Calcular la norma l2, la media y el desvío de cada feature con funciones numpy vectorizadas.\n",
    "7. Agregar una columna a partir de generar una variable aleatoria exponencial a todos los puntos.\n",
    "8. Hacer el histograma de la distribución exponencial.\n",
    "9. Aplicar PCA al dataset reduciendo a 2 dimensiones y graficar el cluster.\n",
    "10. Hacer la clusterización con el k-means desarrollado en clase.\n",
    "11. Volver a graficar el cluster con lo obtenido en (10) y comparar resultados con (9).\n",
    "12. Analizar que pasa si los clusters comienzan a tener overlapping.'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
